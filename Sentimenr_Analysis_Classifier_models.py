# -*- coding: utf-8 -*-
"""DhanushSR_ibmskillbuild_edunet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XyNo1yLKiXix8CcyrwW_c4UerbbZgY9-

#MOUNTING THE GOOGLE DRIVE TO COLAB
"""

from google.colab import drive
drive.mount('/content/drive')

"""#IMPORTING THE DATASET FORM DRIVE"""

# Importing the libraries
import numpy as np
import pandas as pd

# Importing the dataset
dataset = pd.read_csv('/content/drive/MyDrive/ibmskillbuild project/Restaurant_Reviews.tsv', delimiter = '\t', quoting = 3)

dataset.head(10)

dataset.sample(10)

"""#TEXT CLEANING"""

import nltk
nltk.download('stopwords')

import string
from nltk.corpus import stopwords

stopwords.words('english')

[punc for punc in string.punctuation]

def text_process(msg):
  nopunc = [char for char in msg if char not in string.punctuation]
  nopunc = ''.join(nopunc)
  return ' '.join([word for word in nopunc.split() if word.lower() not in stopwords.words('english')])

"""Creating a column for adding the cleaned and Tokenized Review"""

dataset['tokenized_Review'] = dataset['Review'].apply(text_process)

dataset.head(10)

from sklearn.feature_extraction.text import CountVectorizer

vectorizer = CountVectorizer(max_df=0.9,min_df=10)
X = vectorizer.fit_transform(dataset['tokenized_Review']).toarray()

X

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(dataset['tokenized_Review'],dataset['Liked'],random_state=107,test_size=0.2)

X_train.head()

train_vectorized = vectorizer.transform(X_train)
test_vectorized = vectorizer.transform(X_test)

X_train_array = train_vectorized.toarray()
X_test_array = test_vectorized.toarray()

"""#GAUSSIAN NB"""

from sklearn.naive_bayes import GaussianNB
nb = GaussianNB()
nb.fit(X_train_array,y_train)

y_train_preds_nb = nb.predict(X_train_array)
y_test_preds_nb = nb.predict(X_test_array)

# Accuracy, Precision and Recall
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix

def print_metrics(actual_training,predicted_training , actual_testing, predicted_testing):


    # Training Scores
    acc_train = accuracy_score(actual_training,predicted_training)
    pre_train = precision_score(actual_training,predicted_training)
    recall_train = recall_score(actual_training,predicted_training)
    f1_train = f1_score(actual_training,predicted_training)
    roc_score_train = roc_auc_score(actual_training,predicted_training)
    confmat_train = confusion_matrix(actual_training,predicted_training)

    #Testing score
    acc_test = accuracy_score(actual_testing,predicted_testing)
    pre_test = precision_score(actual_testing,predicted_testing)
    recall_test = recall_score(actual_testing,predicted_testing)
    f1_test = f1_score(actual_testing,predicted_testing)
    roc_score_test = roc_auc_score(actual_testing,predicted_testing)
    confmat_test = confusion_matrix(actual_testing,predicted_testing)


    print('ACCURACY SCORE')
    print('Training accuracy_score is : ',round(acc_train*100,2),"%")
    print('Testing accuracy_score is : ',round(acc_test*100,2),"%")
    print('\n=====================================================\n')
    print('PRECISION SCORE')
    print('Training precision_score is : ',round(pre_train*100,2),"%")
    print('Testing precision_score is : ',round(pre_test*100,2),"%")
    print('\n=====================================================\n')
    print('RECALL SCORE')
    print('Training recall_score is : ',round(recall_train*100,2),"%")
    print('Testing recall_score is : ',round(recall_test*100,2),"%")
    print('\n=====================================================\n')
    print('F1 SCORE')
    print('Training f1_score is : ',round(f1_train*100,2),"%")
    print('Testing f1_score is : ',round(f1_test*100,2),"%")
    print('\n=====================================================\n')
    print('ROC_AUC_SCORE')
    print('Training roc_auc_score is : ',round(roc_score_train*100,2),"%")
    print('Testing roc_auc_score is : ',round(roc_score_test*100,2),"%")
    print('\n=====================================================\n')
    print('CONFUSION MATRIX')
    print('Training Confusion_matrix is : ')
    print(confmat_train)
    print('Testing Confusion_matrix is : ')
    print(confmat_test)

#Printing the METRICS for the model
print_metrics(y_train,y_train_preds_nb , y_test,y_test_preds_nb)

"""###PREDICT NEW REVIEW WITH THE MODEL"""

import re
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer

def predict_sentiment(sample_review):

	sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ',string=sample_review)
	sample_review = sample_review.lower()
	sample_review_words = sample_review.split()
	sample_review_words = [word for word in sample_review_words if not word in set(stopwords.words('english'))]
	ps = PorterStemmer()
	final_review = [ps.stem(word) for word in sample_review_words]
	final_review = ' '.join(final_review)

	temp = vectorizer.transform([final_review]).toarray()
	return nb.predict(temp)

def predict_review(sample_review):
	if predict_sentiment(sample_review):
		print('this is a positive review')
	else:
		print('this is a negative review')


sample_review1  = 'Food is Decent bro'
sample_review2 = 'Hmm I like Lovely'
predict_review(sample_review1)
predict_review(sample_review2)



"""#MULTINOMIAL NB"""

# Multinomial NB

# Fitting Naive Bayes to the Training set
from sklearn.naive_bayes import MultinomialNB
mnb = MultinomialNB(alpha=0.1)
mnb.fit(X_train_array,y_train)

y_train_preds_mnb = mnb.predict(X_train_array)
y_test_preds_mnb = mnb.predict(X_test_array)

# Accuracy, Precision and Recall
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix

def print_metrics(actual_training,predicted_training , actual_testing, predicted_testing):


    # Training Scores
    acc_train = accuracy_score(actual_training,predicted_training)
    pre_train = precision_score(actual_training,predicted_training)
    recall_train = recall_score(actual_training,predicted_training)
    f1_train = f1_score(actual_training,predicted_training)
    roc_score_train = roc_auc_score(actual_training,predicted_training)
    confmat_train = confusion_matrix(actual_training,predicted_training)

    #Testing score
    acc_test = accuracy_score(actual_testing,predicted_testing)
    pre_test = precision_score(actual_testing,predicted_testing)
    recall_test = recall_score(actual_testing,predicted_testing)
    f1_test = f1_score(actual_testing,predicted_testing)
    roc_score_test = roc_auc_score(actual_testing,predicted_testing)
    confmat_test = confusion_matrix(actual_testing,predicted_testing)


    print('ACCURACY SCORE')
    print('Training accuracy_score is : ',round(acc_train*100,2),"%")
    print('Testing accuracy_score is : ',round(acc_test*100,2),"%")
    print('\n=====================================================\n')
    print('PRECISION SCORE')
    print('Training precision_score is : ',round(pre_train*100,2),"%")
    print('Testing precision_score is : ',round(pre_test*100,2),"%")
    print('\n=====================================================\n')
    print('RECALL SCORE')
    print('Training recall_score is : ',round(recall_train*100,2),"%")
    print('Testing recall_score is : ',round(recall_test*100,2),"%")
    print('\n=====================================================\n')
    print('F1 SCORE')
    print('Training f1_score is : ',round(f1_train*100,2),"%")
    print('Testing f1_score is : ',round(f1_test*100,2),"%")
    print('\n=====================================================\n')
    print('ROC_AUC_SCORE')
    print('Training roc_auc_score is : ',round(roc_score_train*100,2),"%")
    print('Testing roc_auc_score is : ',round(roc_score_test*100,2),"%")
    print('\n=====================================================\n')
    print('CONFUSION MATRIX')
    print('Training Confusion_matrix is : ')
    print(confmat_train)
    print('Testing Confusion_matrix is : ')
    print(confmat_test)

#Printing the METRICS for the model
print_metrics(y_train,y_train_preds_mnb , y_test,y_test_preds_mnb)

"""### Hyperparameter Tuning for Multinomial NB Classifier"""

#hyperparameter tuning the Naive Bayes Classifier
best_accuracy = 0.0
alpha_val = 0.0
for i in np.arange(0.1,1.1,0.1):
	temp_classifier_MNB = MultinomialNB(alpha=i)

	temp_classifier_MNB.fit(X_train_array,y_train)

	temp_y_pred_MNB = temp_classifier_MNB.predict(X_test_array)

	score_MNB = accuracy_score(y_test,temp_y_pred_MNB)

	print("Accuracy socre for Alpha={} is: {}%".format(round(i,1),round(score_MNB*100,2)))
	if score_MNB>best_accuracy:
		best_accuracy = score_MNB
		alpha_val = i
print('-------------------------------------------')
print('The best accuracy is {}% with alpha value as {}'.format(round(best_accuracy*100,2),round(alpha_val,1)))

"""###PREDICT NEW REVIEW WITH THE MULTINOMIAL NB model"""

import re
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer

def predict_sentiment(sample_review):

	sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ',string=sample_review)
	sample_review = sample_review.lower()
	sample_review_words = sample_review.split()
	sample_review_words = [word for word in sample_review_words if not word in set(stopwords.words('english'))]
	ps = PorterStemmer()
	final_review = [ps.stem(word) for word in sample_review_words]
	final_review = ' '.join(final_review)

	temp = vectorizer.transform([final_review]).toarray()
	return mnb.predict(temp)




def predict_review(sample_review):
	if predict_sentiment(sample_review):
		print('this is a positive review')
	else:
		print('this is a negative review')


sample_review1  = 'Samma da, food was very nice'
sample_review2 = 'Thuu, food is like shit'
predict_review(sample_review1)
predict_review(sample_review2)



"""#BEROUNLLI NAIVE BAYES"""

# Bernoulli NB

# Fitting Bernoulli Naive Bayes to the Training set
from sklearn.naive_bayes import BernoulliNB
bnb = BernoulliNB(alpha=0.3)
bnb.fit(X_train_array, y_train)

y_train_preds_bnb = bnb.predict(X_train_array)
y_test_preds_bnb = bnb.predict(X_test_array)

# Accuracy, Precision and Recall
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix

def print_metrics(actual_training,predicted_training , actual_testing, predicted_testing):


    # Training Scores
    acc_train = accuracy_score(actual_training,predicted_training)
    pre_train = precision_score(actual_training,predicted_training)
    recall_train = recall_score(actual_training,predicted_training)
    f1_train = f1_score(actual_training,predicted_training)
    roc_score_train = roc_auc_score(actual_training,predicted_training)
    confmat_train = confusion_matrix(actual_training,predicted_training)

    #Testing score
    acc_test = accuracy_score(actual_testing,predicted_testing)
    pre_test = precision_score(actual_testing,predicted_testing)
    recall_test = recall_score(actual_testing,predicted_testing)
    f1_test = f1_score(actual_testing,predicted_testing)
    roc_score_test = roc_auc_score(actual_testing,predicted_testing)
    confmat_test = confusion_matrix(actual_testing,predicted_testing)


    print('ACCURACY SCORE')
    print('Training accuracy_score is : ',round(acc_train*100,2),"%")
    print('Testing accuracy_score is : ',round(acc_test*100,2),"%")
    print('\n=====================================================\n')
    print('PRECISION SCORE')
    print('Training precision_score is : ',round(pre_train*100,2),"%")
    print('Testing precision_score is : ',round(pre_test*100,2),"%")
    print('\n=====================================================\n')
    print('RECALL SCORE')
    print('Training recall_score is : ',round(recall_train*100,2),"%")
    print('Testing recall_score is : ',round(recall_test*100,2),"%")
    print('\n=====================================================\n')
    print('F1 SCORE')
    print('Training f1_score is : ',round(f1_train*100,2),"%")
    print('Testing f1_score is : ',round(f1_test*100,2),"%")
    print('\n=====================================================\n')
    print('ROC_AUC_SCORE')
    print('Training roc_auc_score is : ',round(roc_score_train*100,2),"%")
    print('Testing roc_auc_score is : ',round(roc_score_test*100,2),"%")
    print('\n=====================================================\n')
    print('CONFUSION MATRIX')
    print('Training Confusion_matrix is : ')
    print(confmat_train)
    print('Testing Confusion_matrix is : ')
    print(confmat_test)

#Printing the METRICS for the model
print_metrics(y_train,y_train_preds_bnb , y_test,y_test_preds_bnb)



"""### hyperparameter Tuning for Bernoulli NB"""

best_accuracy = 0.0
alpha_val = 0.0
for i in np.arange(0.1,1.1,0.1):
	temp_classifier_BNB = BernoulliNB(alpha=i)

	temp_classifier_BNB.fit(X_train_array,y_train)

	temp_y_pred_BNB = temp_classifier_BNB.predict(X_test_array)

	score_BNB = accuracy_score(y_test,temp_y_pred_BNB)

	print("Accuracy socre for Alpha={} is: {}%".format(round(i,1),round(score_BNB*100,2)))
	if score_BNB>best_accuracy:
		best_accuracy = score_BNB
		alpha_val = i
print('-------------------------------------------')
print('The best accuracy is {}% with alpha value as {}'.format(round(best_accuracy*100,2),round(alpha_val,1)))



"""### Predict New Review with this Model"""

import re
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer

def predict_sentiment(sample_review):

	sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ',string=sample_review)
	sample_review = sample_review.lower()
	sample_review_words = sample_review.split()
	sample_review_words = [word for word in sample_review_words if not word in set(stopwords.words('english'))]
	ps = PorterStemmer()
	final_review = [ps.stem(word) for word in sample_review_words]
	final_review = ' '.join(final_review)

	temp = vectorizer.transform([final_review]).toarray()
	return bnb.predict(temp)




def predict_review(sample_review):
	if predict_sentiment(sample_review):
		print('this is a positive review')
	else:
		print('this is a negative review')


sample_review1  = 'Samma da, food was very nice'
sample_review2 = 'Thuu, food is like shit'
predict_review(sample_review1)
predict_review(sample_review2)



"""#Complement Naive Bayes"""

# Complement NB
from sklearn.naive_bayes import ComplementNB

# Create a Complement Naive Bayes classifier
cnb = ComplementNB(alpha=0.4)

# Fit the model on the training data
cnb.fit(X_train_array, y_train)

# Make predictions on the training and test data
y_train_preds_cnb = cnb.predict(X_train_array)
y_test_preds_cnb = cnb.predict(X_test_array)

# Accuracy, Precision and Recall
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix

def print_metrics(actual_training,predicted_training , actual_testing, predicted_testing):


    # Training Scores
    acc_train = accuracy_score(actual_training,predicted_training)
    pre_train = precision_score(actual_training,predicted_training)
    recall_train = recall_score(actual_training,predicted_training)
    f1_train = f1_score(actual_training,predicted_training)
    roc_score_train = roc_auc_score(actual_training,predicted_training)
    confmat_train = confusion_matrix(actual_training,predicted_training)

    #Testing score
    acc_test = accuracy_score(actual_testing,predicted_testing)
    pre_test = precision_score(actual_testing,predicted_testing)
    recall_test = recall_score(actual_testing,predicted_testing)
    f1_test = f1_score(actual_testing,predicted_testing)
    roc_score_test = roc_auc_score(actual_testing,predicted_testing)
    confmat_test = confusion_matrix(actual_testing,predicted_testing)


    print('ACCURACY SCORE')
    print('Training accuracy_score is : ',round(acc_train*100,2),"%")
    print('Testing accuracy_score is : ',round(acc_test*100,2),"%")
    print('\n=====================================================\n')
    print('PRECISION SCORE')
    print('Training precision_score is : ',round(pre_train*100,2),"%")
    print('Testing precision_score is : ',round(pre_test*100,2),"%")
    print('\n=====================================================\n')
    print('RECALL SCORE')
    print('Training recall_score is : ',round(recall_train*100,2),"%")
    print('Testing recall_score is : ',round(recall_test*100,2),"%")
    print('\n=====================================================\n')
    print('F1 SCORE')
    print('Training f1_score is : ',round(f1_train*100,2),"%")
    print('Testing f1_score is : ',round(f1_test*100,2),"%")
    print('\n=====================================================\n')
    print('ROC_AUC_SCORE')
    print('Training roc_auc_score is : ',round(roc_score_train*100,2),"%")
    print('Testing roc_auc_score is : ',round(roc_score_test*100,2),"%")
    print('\n=====================================================\n')
    print('CONFUSION MATRIX')
    print('Training Confusion_matrix is : ')
    print(confmat_train)
    print('Testing Confusion_matrix is : ')
    print(confmat_test)

#Printing the METRICS for the model
print_metrics(y_train,y_train_preds_cnb , y_test,y_test_preds_cnb)

"""###Hyperparameter Tuning for Complement NB"""

best_accuracy = 0.0
alpha_val = 0.0
for i in np.arange(0.1,1.1,0.1):
	temp_classifier_CNB = ComplementNB(alpha=i)

	temp_classifier_CNB.fit(X_train_array,y_train)

	temp_y_pred_CNB = temp_classifier_CNB.predict(X_test_array)

	score_CNB = accuracy_score(y_test,temp_y_pred_CNB)

	print("Accuracy socre for Alpha={} is: {}%".format(round(i,1),round(score_CNB*100,2)))
	if score_CNB>best_accuracy:
		best_accuracy = score_CNB
		alpha_val = i
print('-------------------------------------------')
print('The best accuracy is {}% with alpha value as {}'.format(round(best_accuracy*100,2),round(alpha_val,1)))

"""### PREDICTING THE NEW REVIEW WITH THIS MODEL"""

import re
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer

def predict_sentiment(sample_review):

	sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ',string=sample_review)
	sample_review = sample_review.lower()
	sample_review_words = sample_review.split()
	sample_review_words = [word for word in sample_review_words if not word in set(stopwords.words('english'))]
	ps = PorterStemmer()
	final_review = [ps.stem(word) for word in sample_review_words]
	final_review = ' '.join(final_review)

	temp = vectorizer.transform([final_review]).toarray()
	return cnb.predict(temp)




def predict_review(sample_review):
	if predict_sentiment(sample_review):
		print('this is a positive review')
	else:
		print('this is a negative review')


sample_review1  = 'Samma da, food was very nice'
sample_review2 = 'Thuu, food is like shit'
predict_review(sample_review1)
predict_review(sample_review2)



"""#LOGISTIC REGRESSION"""

# Import the Logistic Regression class
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression(C=1.0)

# Fit the Logistic Regression model to the training data
lr.fit(X_train_array, y_train)

# Make predictions on the training and test data
y_train_preds_lr = lr.predict(X_train_array)
y_test_preds_lr = lr.predict(X_test_array)

# Accuracy, Precision and Recall
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix

def print_metrics(actual_training,predicted_training , actual_testing, predicted_testing):


    # Training Scores
    acc_train = accuracy_score(actual_training,predicted_training)
    pre_train = precision_score(actual_training,predicted_training)
    recall_train = recall_score(actual_training,predicted_training)
    f1_train = f1_score(actual_training,predicted_training)
    roc_score_train = roc_auc_score(actual_training,predicted_training)
    confmat_train = confusion_matrix(actual_training,predicted_training)

    #Testing score
    acc_test = accuracy_score(actual_testing,predicted_testing)
    pre_test = precision_score(actual_testing,predicted_testing)
    recall_test = recall_score(actual_testing,predicted_testing)
    f1_test = f1_score(actual_testing,predicted_testing)
    roc_score_test = roc_auc_score(actual_testing,predicted_testing)
    confmat_test = confusion_matrix(actual_testing,predicted_testing)


    print('ACCURACY SCORE')
    print('Training accuracy_score is : ',round(acc_train*100,2),"%")
    print('Testing accuracy_score is : ',round(acc_test*100,2),"%")
    print('\n=====================================================\n')
    print('PRECISION SCORE')
    print('Training precision_score is : ',round(pre_train*100,2),"%")
    print('Testing precision_score is : ',round(pre_test*100,2),"%")
    print('\n=====================================================\n')
    print('RECALL SCORE')
    print('Training recall_score is : ',round(recall_train*100,2),"%")
    print('Testing recall_score is : ',round(recall_test*100,2),"%")
    print('\n=====================================================\n')
    print('F1 SCORE')
    print('Training f1_score is : ',round(f1_train*100,2),"%")
    print('Testing f1_score is : ',round(f1_test*100,2),"%")
    print('\n=====================================================\n')
    print('ROC_AUC_SCORE')
    print('Training roc_auc_score is : ',round(roc_score_train*100,2),"%")
    print('Testing roc_auc_score is : ',round(roc_score_test*100,2),"%")
    print('\n=====================================================\n')
    print('CONFUSION MATRIX')
    print('Training Confusion_matrix is : ')
    print(confmat_train)
    print('Testing Confusion_matrix is : ')
    print(confmat_test)

#Printing the METRICS for the model
print_metrics(y_train,y_train_preds_lr , y_test,y_test_preds_lr)

"""###Hyperparameter Tuning for Logistic Regression"""

best_accuracy = 0.0
alpha_val = 0.0
for i in np.arange(0.1,1.1,0.1):
	temp_classifier_LR = LogisticRegression(C=i)

	temp_classifier_LR.fit(X_train_array,y_train)

	temp_y_pred_LR = temp_classifier_LR.predict(X_test_array)

	score_LR = accuracy_score(y_test,temp_y_pred_LR)

	print("Accuracy socre for C={} is: {}%".format(round(i,1),round(score_LR*100,2)))
	if score_CNB>best_accuracy:
		best_accuracy = score_LR
		alpha_val = i
print('-------------------------------------------')
print('The best accuracy is {}% with C value as {}'.format(round(best_accuracy*100,2),round(alpha_val,1)))

"""###PREDICTING WITH CUSTOM REVIEW WITH THIS MODEL"""

import re
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer

def predict_sentiment(sample_review):

	sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ',string=sample_review)
	sample_review = sample_review.lower()
	sample_review_words = sample_review.split()
	sample_review_words = [word for word in sample_review_words if not word in set(stopwords.words('english'))]
	ps = PorterStemmer()
	final_review = [ps.stem(word) for word in sample_review_words]
	final_review = ' '.join(final_review)

	temp = vectorizer.transform([final_review]).toarray()
	return lr.predict(temp)




def predict_review(sample_review):
	if predict_sentiment(sample_review):
		print('this is a positive review')
	else:
		print('this is a negative review')


sample_review1  = 'Mame, sapadu was fine, they could have kept more side dish'
sample_review2 = 'Dei sambar ah da was like dog shit'
predict_review(sample_review1)
predict_review(sample_review2)

"""# K NEAREST NEIGHBOUR (KNN)"""

# Import the KNeighborsClassifier class from scikit-learn
from sklearn.neighbors import KNeighborsClassifier

# Create a KNN classifier with a specified number of neighbors (e.g., n_neighbors=5)
knn = KNeighborsClassifier(n_neighbors=3)

# Fit the KNN classifier to the training data
knn.fit(X_train_array, y_train)

# Make predictions on the training set
y_train_preds_knn = knn.predict(X_train_array)

# Make predictions on the test set
y_test_preds_knn = knn.predict(X_test_array)

# Accuracy, Precision and Recall
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix

def print_metrics(actual_training,predicted_training , actual_testing, predicted_testing):


    # Training Scores
    acc_train = accuracy_score(actual_training,predicted_training)
    pre_train = precision_score(actual_training,predicted_training)
    recall_train = recall_score(actual_training,predicted_training)
    f1_train = f1_score(actual_training,predicted_training)
    roc_score_train = roc_auc_score(actual_training,predicted_training)
    confmat_train = confusion_matrix(actual_training,predicted_training)

    #Testing score
    acc_test = accuracy_score(actual_testing,predicted_testing)
    pre_test = precision_score(actual_testing,predicted_testing)
    recall_test = recall_score(actual_testing,predicted_testing)
    f1_test = f1_score(actual_testing,predicted_testing)
    roc_score_test = roc_auc_score(actual_testing,predicted_testing)
    confmat_test = confusion_matrix(actual_testing,predicted_testing)


    print('ACCURACY SCORE')
    print('Training accuracy_score is : ',round(acc_train*100,2),"%")
    print('Testing accuracy_score is : ',round(acc_test*100,2),"%")
    print('\n=====================================================\n')
    print('PRECISION SCORE')
    print('Training precision_score is : ',round(pre_train*100,2),"%")
    print('Testing precision_score is : ',round(pre_test*100,2),"%")
    print('\n=====================================================\n')
    print('RECALL SCORE')
    print('Training recall_score is : ',round(recall_train*100,2),"%")
    print('Testing recall_score is : ',round(recall_test*100,2),"%")
    print('\n=====================================================\n')
    print('F1 SCORE')
    print('Training f1_score is : ',round(f1_train*100,2),"%")
    print('Testing f1_score is : ',round(f1_test*100,2),"%")
    print('\n=====================================================\n')
    print('ROC_AUC_SCORE')
    print('Training roc_auc_score is : ',round(roc_score_train*100,2),"%")
    print('Testing roc_auc_score is : ',round(roc_score_test*100,2),"%")
    print('\n=====================================================\n')
    print('CONFUSION MATRIX')
    print('Training Confusion_matrix is : ')
    print(confmat_train)
    print('Testing Confusion_matrix is : ')
    print(confmat_test)

#Printing the METRICS for the model
print_metrics(y_train,y_train_preds_knn , y_test,y_test_preds_knn)

"""### Hyperparameter Tuning for KNN"""

best_accuracy = 0.0
alpha_val = 0.0
for i in np.arange(1,11,1):
	temp_classifier_KNN = KNeighborsClassifier(n_neighbors=i)

	temp_classifier_KNN.fit(X_train_array,y_train)

	temp_y_pred_KNN = temp_classifier_KNN.predict(X_test_array)

	score_KNN = accuracy_score(y_test,temp_y_pred_KNN)

	print("Accuracy socre for n_neighbors={} is: {}%".format(round(i,1),round(score_KNN*100,2)))
	if score_KNN>best_accuracy:
		best_accuracy = score_KNN
		alpha_val = i
print('-------------------------------------------')
print('The best accuracy is {}% with n_neighbors value as {}'.format(round(best_accuracy*100,2),round(alpha_val,1)))



"""### PREDICTING NEW REVIEW WITH KNN"""

import re
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer

def predict_sentiment(sample_review):

	sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ',string=sample_review)
	sample_review = sample_review.lower()
	sample_review_words = sample_review.split()
	sample_review_words = [word for word in sample_review_words if not word in set(stopwords.words('english'))]
	ps = PorterStemmer()
	final_review = [ps.stem(word) for word in sample_review_words]
	final_review = ' '.join(final_review)

	temp = vectorizer.transform([final_review]).toarray()
	return knn.predict(temp)




def predict_review(sample_review):
	if predict_sentiment(sample_review):
		print('this is a positive review')
	else:
		print('this is a negative review')


sample_review_knn = 'I am going to be honest , the food was bad , sorry'
predict_review(sample_review_knn)



"""#DECISION TREES"""

# Import the Decision Tree classifier
from sklearn.tree import DecisionTreeClassifier


dt = DecisionTreeClassifier(max_depth=11, random_state=14)

# Fit the Decision Tree classifier to the training data
dt.fit(X_train_array, y_train)

# Make predictions on the training set
y_train_preds_dt = dt.predict(X_train_array)

# Make predictions on the test set
y_test_preds_dt = dt.predict(X_test_array)

# Accuracy, Precision and Recall
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import roc_auc_score
from sklearn.metrics import confusion_matrix

def print_metrics(actual_training,predicted_training , actual_testing, predicted_testing):


    # Training Scores
    acc_train = accuracy_score(actual_training,predicted_training)
    pre_train = precision_score(actual_training,predicted_training)
    recall_train = recall_score(actual_training,predicted_training)
    f1_train = f1_score(actual_training,predicted_training)
    roc_score_train = roc_auc_score(actual_training,predicted_training)
    confmat_train = confusion_matrix(actual_training,predicted_training)

    #Testing score
    acc_test = accuracy_score(actual_testing,predicted_testing)
    pre_test = precision_score(actual_testing,predicted_testing)
    recall_test = recall_score(actual_testing,predicted_testing)
    f1_test = f1_score(actual_testing,predicted_testing)
    roc_score_test = roc_auc_score(actual_testing,predicted_testing)
    confmat_test = confusion_matrix(actual_testing,predicted_testing)


    print('ACCURACY SCORE')
    print('Training accuracy_score is : ',round(acc_train*100,2),"%")
    print('Testing accuracy_score is : ',round(acc_test*100,2),"%")
    print('\n=====================================================\n')
    print('PRECISION SCORE')
    print('Training precision_score is : ',round(pre_train*100,2),"%")
    print('Testing precision_score is : ',round(pre_test*100,2),"%")
    print('\n=====================================================\n')
    print('RECALL SCORE')
    print('Training recall_score is : ',round(recall_train*100,2),"%")
    print('Testing recall_score is : ',round(recall_test*100,2),"%")
    print('\n=====================================================\n')
    print('F1 SCORE')
    print('Training f1_score is : ',round(f1_train*100,2),"%")
    print('Testing f1_score is : ',round(f1_test*100,2),"%")
    print('\n=====================================================\n')
    print('ROC_AUC_SCORE')
    print('Training roc_auc_score is : ',round(roc_score_train*100,2),"%")
    print('Testing roc_auc_score is : ',round(roc_score_test*100,2),"%")
    print('\n=====================================================\n')
    print('CONFUSION MATRIX')
    print('Training Confusion_matrix is : ')
    print(confmat_train)
    print('Testing Confusion_matrix is : ')
    print(confmat_test)

#Printing the METRICS for the model
print_metrics(y_train,y_train_preds_dt , y_test,y_test_preds_dt)

"""### HyperParameter Tuning for Decision Tree"""

best_accuracy = 0.0
best_max_depth = 0
best_random_state = 0

for i in np.arange(3, 10, 1):
    for j in np.arange(10, 25, 1):
        temp_classifier_DT = DecisionTreeClassifier(max_depth=i, random_state=j)
        temp_classifier_DT.fit(X_train_array, y_train)
        temp_y_pred_DT = temp_classifier_DT.predict(X_test_array)
        score_DT = accuracy_score(y_test, temp_y_pred_DT)
        print("Accuracy score for max_depth={} and random_state={} is: {}%".format(round(i, 1), round(j, 1), round(score_RF * 100, 2)))
        if score_RF > best_accuracy:
            best_accuracy = score_DT
            best_max_depth = i
            best_random_state = j

print('-------------------------------------------')
print('The best accuracy is {}% with max_depth={} and random_state={}'.format(round(best_accuracy * 100, 2), best_max_depth, best_random_state))



"""###PREDICTING NEW REVIEWS WITH DECISION TREE

"""

import re
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from sklearn.feature_extraction.text import CountVectorizer

def predict_sentiment(sample_review):

	sample_review = re.sub(pattern='[^a-zA-Z]',repl=' ',string=sample_review)
	sample_review = sample_review.lower()
	sample_review_words = sample_review.split()
	sample_review_words = [word for word in sample_review_words if not word in set(stopwords.words('english'))]
	ps = PorterStemmer()
	final_review = [ps.stem(word) for word in sample_review_words]
	final_review = ' '.join(final_review)

	temp = vectorizer.transform([final_review]).toarray()
	return rf.predict(temp)

def predict_review(sample_review):
	if predict_sentiment(sample_review):
		print('this is a positive review')
	else:
		print('this is a negative review')


sample_review_dt  = 'nice nice nice '
predict_review(sample_review_dt)

